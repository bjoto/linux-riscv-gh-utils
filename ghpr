#!/bin/env python3

from github import Github
from github import Auth
import argparse
import os
import re
import requests
import sys

# --8<-- from KPD ---
from enum import Enum
from typing import Iterable, Optional

class Status(Enum):
    SKIPPED = "skipped"
    PENDING = "pending"
    SUCCESS = "success"
    FAILURE = "failure"
    CONFLICT = "conflict"


def gh_conclusion_to_status(gh_conclusion: Optional[str]) -> Status:
    """Translate a GitHub conclusion to our `Status` enum."""
    # GitHub reports pending jobs with a `None` conclusion.
    if gh_conclusion is None:
        return Status.PENDING

    # See
    # https://docs.github.com/en/rest/checks/suites?apiVersion=2022-11-28#get-a-check-suite
    # for a list of conclusions.
    if gh_conclusion in (
        "failure",
        "timed_out",
        "action_required",
        "startup_failure",
        "stale",
    ):
        return Status.FAILURE

    if gh_conclusion in ("cancelled",):
        return Status.PENDING

    # A "success" overwrites any skips, as the latter are effectively
    # neutral.
    if gh_conclusion in ("success",):
        return Status.SUCCESS

    return Status.SKIPPED


def process_statuses(statuses: Iterable[Status]) -> Status:
    """Boil down a set of `Status` objects into a single one."""
    final = Status.SKIPPED
    for status in statuses:
        if status == Status.FAILURE:
            # "failure" is sticky.
            return status
        elif status == Status.PENDING:
            final = status
        elif status == Status.SUCCESS:
            if final != Status.PENDING:
                final = status
        else:
            # We ignore anything classified as `Skipped`, as that's the
            # starting state and we treat it as "neutral".
            pass
    return final
# --8<--

def print_pr(pr, args):
    print(f"title: {pr.title}")
    print(f"url: https://github.com/linux-riscv/linux-riscv/pull/{pr.number}")
    l = [i.name for i in pr.labels]
    l.sort()
    print(f"labels: {' '.join(str(i) for i in l)}")
    if args.show_body:
        msg = pr.body.splitlines()
        for i in msg:
            print(f"body: {i}")

    if args.show_last_messages:
        comments = pr.get_issue_comments();
        show = (args.show_last_messages
                if args.show_last_messages < comments.totalCount
                else comments.totalCount)
        for i in range(show):
            msg = comments[comments.totalCount-1-i].body.splitlines()
            for m in msg:
                print(f"msg#{comments.totalCount-1-i}: {m}")

    if args.show_suite:
        CI_APP = 15368
        commit = r.get_commit(pr.head.sha)
        suites = commit.get_check_suites()
        conclusion = "NONE"
        status = "NONE"
        for s in suites:
            if s.app.id == CI_APP:
                conclusion = s.conclusion
                status = s.status
                break

        print(f"suite_status: {status}")
        print(f"suite_conclusion: {conclusion}")

def print_workflow(pr):
    wrs = r.get_workflow_runs(head_sha=pr.head.sha)
    w = None
    for i in wrs:
        if i.name == "linux-riscv-ci-patches":
            w = i
            break
    if w:
        j = None
        for i in w.jobs():
            if i.name == "build-patches":
                j = i
                break

        if j:
            logs_url = j.logs_url()
            logs = requests.get(logs_url, allow_redirects=True)
            logs = logs.content.decode('utf-8')
            strs = logs.splitlines()

            reg = ".*##.*](OK|FAIL|WARN).*Patch (\d?\d?\d+)/.*Test (\d?\d?\d+)/\d?\d?\d+: (.*)"
            p = re.compile(reg)
            res = {}
            err = 0
            warn = 0
            ok = 0
            for i in strs:
                m = p.match(i)
                if m:
                    status = m.group(1)
                    patchnum = int(m.group(2))
                    testnum = int(m.group(3))
                    test = m.group(4)
                    if patchnum not in res:
                        res[patchnum] = {}
                    if testnum in res[patchnum]:
                            print(f"Multiple tests with same id: patch {patchnum}: test: {testnum}: {test}")
                    res[patchnum][testnum] = {}
                    if status == "OK":
                        state = "success"
                        ok += 1
                    elif status == "WARN":
                        state = "warning"
                        warn += 1
                    else:
                        state = "failure"
                        err += 1
                    res[patchnum][testnum]["status"] = state
                    res[patchnum][testnum]["test"] = test

            if err:
                res["conclusion"] = "failure"
            elif warn:
                res["conclusion"] = "warning"
            elif ok:
                res["conclusion"] = "success"

            for i in range(1, len(res)):
                for j in range(1, len(res[i]) + 1):
                    print(f'patch{i:02}_test{j:02}: {res[i][j]["status"]} {res[i][j]["test"]} ')
            print(f'conclusion: {res["conclusion"]}')

def print_kpd_debug(pr):
    statuses = []
    jobs = []

    runs = r.get_workflow_runs(head_sha=pr.head.sha)
    for run in runs:
        status = gh_conclusion_to_status(run.conclusion)
        print(f"run: {run.name} {run.run_started_at} {run.conclusion} {run.status} {status}")
        run_jobs = run.jobs()

        if status == Status.FAILURE:
            for job in run_jobs:
                print(f"  job: '{job.name}' conclusion: {job.conclusion} status: {job.status}")
                for step in job.steps:
                    print(f"    step: '{step.name}' conclusion: {step.conclusion} status: {step.status}")
                    if step.conclusion is None or step.conclusion == "cancelled":
                        print(
                            f"    step: '{step.name}' of {run} was interrupted/canceled; marking workflow as pending"
                        )
                        status = Status.PENDING
                        break

        statuses.append(status)
        jobs += run_jobs

    status = process_statuses(statuses)
    jobs = sorted(jobs, key=lambda job: job.name)
    jobs_logs = [
        f"{job.conclusion} -> {gh_conclusion_to_status(job.conclusion)} ({job.html_url})"
        for job in jobs
    ]

    print(f"status: overall: '{status}', jobs: '{jobs_logs}")

def print_runs(pr):
    runs = r.get_workflow_runs(head_sha=pr.head.sha)
    for run in runs:
        print(f"run: name='{run.name}' run_started_at='{run.run_started_at}' conclusion='{run.conclusion}' status='{run.status}'")
        if not args.runs_all:
            continue
        run_jobs = run.jobs()
        for job in run_jobs:
            print(f"  job: name='{job.name}' conclusion='{job.conclusion}' status='{job.status}'")
            for step in job.steps:
                print(f"    step: name='{step.name}' conclusion='{step.conclusion}' status='{step.status}'")

def parse_args():
    parser = argparse.ArgumentParser(description=''' Manage
    linux-riscv PRs. The tool expects that the environment variable
    GH_TOKEN contains the Github token.
    ''')

    parser.add_argument(
        "--pr", type=int, action="append", help="Only show PR NUMBER (can be passed multiple times)"
    )

    parser.add_argument(
        "--show-body", action="store_true", help="Show PR body"
    )

    parser.add_argument(
        "--show-suite", action="store_true", help="Show suite details"
    )

    parser.add_argument(
        "--show-workflow", action="store_true", help="Show suite details"
    )

    parser.add_argument(
        "--kpd", action="store_true", help="KPD conclusion debugging"
    )

    parser.add_argument(
        "--runs", action="store_true", help="Dump"
    )
    parser.add_argument(
        "--runs-all", action="store_true", help="Dump"
    )

    parser.add_argument(
        "--show-last-messages", nargs='?', const=1, type=int, metavar="N",
        help="Show last N messages (default 1)"
    )

    return parser.parse_args()

args = parse_args()

token = os.getenv('GH_TOKEN')
auth = Auth.Token(token)
g = Github(auth=auth)
# r = g.get_user().get_repo("linux")
r = g.get_organization("linux-riscv").get_repo("linux-riscv")

if args.pr:
    prs = []
    for i in args.pr:
        pr = r.get_pull(i)
        prs.append(pr)
else:
    prs = r.get_pulls(state="open")

for pr in prs:
    print_pr(pr, args)
    if args.show_workflow:
        print_workflow(pr)
    if args.kpd:
        print_kpd_debug(pr)
    if args.runs or args.runs_all:
        print_runs(pr)

g.close()
