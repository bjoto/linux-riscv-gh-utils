#!/bin/env python3

from github import Github
from github import Auth
import argparse
import os
import re
import requests
import sys

# --8<-- from KPD ---
from enum import Enum
from typing import Iterable, Optional

class Status(Enum):
    SKIPPED = "skipped"
    PENDING = "pending"
    SUCCESS = "success"
    FAILURE = "failure"
    CONFLICT = "conflict"


def gh_conclusion_to_status(gh_conclusion: Optional[str]) -> Status:
    """Translate a GitHub conclusion to our `Status` enum."""
    # GitHub reports pending jobs with a `None` conclusion.
    if gh_conclusion is None:
        return Status.PENDING

    # See
    # https://docs.github.com/en/rest/checks/suites?apiVersion=2022-11-28#get-a-check-suite
    # for a list of conclusions.
    if gh_conclusion in (
        "failure",
        "timed_out",
        "action_required",
        "startup_failure",
        "stale",
    ):
        return Status.FAILURE

    if gh_conclusion in ("cancelled",):
        return Status.PENDING

    # A "success" overwrites any skips, as the latter are effectively
    # neutral.
    if gh_conclusion in ("success",):
        return Status.SUCCESS

    return Status.SKIPPED


def process_statuses(statuses: Iterable[Status]) -> Status:
    """Boil down a set of `Status` objects into a single one."""
    final = Status.SKIPPED
    for status in statuses:
        if status == Status.FAILURE:
            # "failure" is sticky.
            return status
        elif status == Status.PENDING:
            final = status
        elif status == Status.SUCCESS:
            if final != Status.PENDING:
                final = status
        else:
            # We ignore anything classified as `Skipped`, as that's the
            # starting state and we treat it as "neutral".
            pass
    return final
# --8<--

def print_pr(pr, args):
    print(f"title: {pr.title}")
    print(f"url: https://github.com/linux-riscv/linux-riscv/pull/{pr.number}")
    l = [i.name for i in pr.labels]
    l.sort()
    labels = ' '.join(str(i) for i in l)
    if len(labels):
        print(f"labels: {labels}")
    if args.show_body:
        msg = pr.body.splitlines()
        for i in msg:
            print(f"body: {i}")

    if args.show_last_messages:
        comments = pr.get_issue_comments();
        show = (args.show_last_messages
                if args.show_last_messages < comments.totalCount
                else comments.totalCount)
        for i in range(show):
            msg = comments[comments.totalCount-1-i].body.splitlines()
            for m in msg:
                print(f"msg#{comments.totalCount-1-i}: {m}")

    if args.show_suite:
        CI_APP = 15368
        commit = r.get_commit(pr.head.sha)
        suites = commit.get_check_suites()
        conclusion = "NONE"
        status = "NONE"
        for s in suites:
            if s.app.id == CI_APP:
                conclusion = s.conclusion
                status = s.status
                break

        print(f"suite_status: {status}")
        print(f"suite_conclusion: {conclusion}")

def print_patches_workflow(pr):
    wrs = r.get_workflow_runs(head_sha=pr.head.sha)
    w = None
    for i in wrs:
        if i.name == "linux-riscv-ci-patches":
            if i.conclusion == "skipped":
                 return
            w = i
            break
    if w:
        j = None
        for i in w.jobs():
            if i.name == "build-patches":
                j = i
                break

        if j:
            logs_url = j.logs_url()
            logs = requests.get(logs_url, allow_redirects=True)
            logs = logs.content.decode('utf-8')
            strs = logs.splitlines()

            reg = ".*##.*](OK|FAIL|WARN).*Patch (\d?\d?\d+)/.*Test (\d?\d?\d+)/\d?\d?\d+: (.*)"
            p = re.compile(reg)
            res = {}
            err = 0
            warn = 0
            ok = 0
            for i in strs:
                m = p.match(i)
                if m:
                    status = m.group(1)
                    patchnum = int(m.group(2))
                    testnum = int(m.group(3))
                    test = m.group(4)
                    if patchnum not in res:
                        res[patchnum] = {}
                    if testnum in res[patchnum]:
                            print(f"Multiple tests with same id: patch {patchnum}: test: {testnum}: {test}")
                    res[patchnum][testnum] = {}
                    if status == "OK":
                        state = "success"
                        ok += 1
                    elif status == "WARN":
                        state = "warning"
                        warn += 1
                    else:
                        state = "failure"
                        err += 1
                    res[patchnum][testnum]["state"] = status
                    res[patchnum][testnum]["status"] = state
                    res[patchnum][testnum]["test"] = test

            if err:
                res["conclusion"] = "failure"
            elif warn or ok:
                res["conclusion"] = "success"

            for i in range(1, len(res)):
                for j in range(1, len(res[i]) + 1):
                    if args.all_results or res[i][j]["state"] != "OK":
                        print(f'patch{i:02}_test{j:02}: {res[i][j]["state"]} {res[i][j]["test"]}')
            if err + warn + ok:
                print(f'patches: conclusion: {res["conclusion"]} total: {err + warn + ok}')

def print_series_workflow(pr):
    wrs = r.get_workflow_runs(head_sha=pr.head.sha)
    w = None
    for i in wrs:
        if i.name == "linux-riscv-ci-series":
            if i.conclusion == "skipped":
                return
            w = i
            break
    if w:
        j = None
        for i in w.jobs():
            if i.name == "build-series":
                j = i
                break

        if j:
            logs_url = j.logs_url()
            logs = requests.get(logs_url, allow_redirects=True)
            logs = logs.content.decode('utf-8')
            strs = logs.splitlines()

            p_test = re.compile(r".*##.*]Testing (\S+) (\S+)")
            p_test_res = re.compile(r".*##.*](OK|FAIL|WARN) (\S+) (\S+)")
            p_build = re.compile(r".*##.*]Building (\S+)")
            p_build_res = re.compile(r".*##.*](OK|FAIL|WARN) (\S+)")

            is_testing = False
            is_building = False
            m_test = None
            m_build = None
            test_open = 0
            test_close = 0
            build_open = 0
            build_close = 0
            for i in strs:
                if m_test:
                    m = p_test_res.match(i)
                    if m:
                        if m.group(2) != m_test.group(1) or m.group(3) != m_test.group(2):
                            print(f"ERROR: Test mismatch! Corrupt log? Manual check: {j.logs_url()}")
                            sys.exit(1)
                        if args.all_results or m.group(1) != "OK":
                            print(f"booting {m.group(1)}: {os.path.basename(m.group(2))} {os.path.basename(m.group(3))}")
                        test_close += 1
                        m_test = None
                    continue

                if m_build:
                    m = p_build_res.match(i)
                    if m:
                        if m.group(2) != m_build.group(1):
                            print(f"ERROR: Build mismatch! Corrupt log? Manual check: {j.logs_url()}")
                            sys.exit(1)
                        if args.all_results or m.group(1) != "OK":
                            print(f"building {m.group(1)}: {os.path.basename(m.group(2))}")
                        build_close += 1
                        m_build = None
                    continue

                m_test = p_test.match(i)
                if m_test:
                    test_open += 1
                    continue

                m_build = p_build.match(i)
                if m_build:
                    build_open += 1
                    continue
            if test_open != test_close or build_open != build_close:
                print(f"ERROR: Result mismatch! Corrupt log? Manual check: {j.logs_url()}")
                sys.exit(1)
            print(f"series: builds: {build_open} boots: {test_open}")

def print_kpd_debug(pr):
    statuses = []
    jobs = []

    runs = r.get_workflow_runs(head_sha=pr.head.sha)
    for run in runs:
        status = gh_conclusion_to_status(run.conclusion)
        print(f"run: {run.name} {run.run_started_at} {run.conclusion} {run.status} {status}")
        run_jobs = run.jobs()

        if status == Status.FAILURE:
            for job in run_jobs:
                print(f"  job: '{job.name}' conclusion: {job.conclusion} status: {job.status}")
                for step in job.steps:
                    print(f"    step: '{step.name}' conclusion: {step.conclusion} status: {step.status}")
                    if step.conclusion is None or step.conclusion == "cancelled":
                        print(
                            f"    step: '{step.name}' of {run} was interrupted/canceled; marking workflow as pending"
                        )
                        status = Status.PENDING
                        break

        statuses.append(status)
        jobs += run_jobs

    status = process_statuses(statuses)
    jobs = sorted(jobs, key=lambda job: job.name)
    jobs_logs = [
        f"{job.conclusion} -> {gh_conclusion_to_status(job.conclusion)} ({job.html_url})"
        for job in jobs
    ]

    print(f"status: overall: '{status}', jobs: '{jobs_logs}")

def print_runs(pr):
    runs = r.get_workflow_runs(head_sha=pr.head.sha)
    for run in runs:
        print(f"run: name='{run.name}' run_started_at='{run.run_started_at}' conclusion='{run.conclusion}' status='{run.status}' event='{run.event}' prs='{run.pull_requests}'")
        if not args.runs_all:
            continue
        run_jobs = run.jobs()
        for job in run_jobs:
            print(f"  job: name='{job.name}' conclusion='{job.conclusion}' status='{job.status}'")
            for step in job.steps:
                print(f"    step: name='{step.name}' conclusion='{step.conclusion}' status='{step.status}'")

def print_pending_orphans(prs):
    good_runs = set()
    for pr in prs:
        runs = r.get_workflow_runs(head_sha=pr.head.sha)
        for run in runs:
            if run.status == "in_progress" or run.status == "queued":
                good_runs.add(run)

    all_runs = set()
    for run in runs:
        if run.status == "in_progress" or run.status == "queued":
            all_runs.add(run)
    orphan_runs = all_runs.difference(good_runs)
    if len(orphan_runs) == 0:
        print("No orphan runs")
        return
    for run in orphan_runs:
        print(f"orphan: {run}")


def parse_args():
    parser = argparse.ArgumentParser(description=''' Manage
    linux-riscv PRs. The tool expects that the environment variable
    GH_TOKEN contains the Github token.
    ''')

    parser.add_argument(
        "--pr", type=int, action="append", help="Only show PR NUMBER (can be passed multiple times)"
    )

    parser.add_argument(
        "--show-body", action="store_true", help="Show PR body"
    )

    parser.add_argument(
        "--show-suite", action="store_true", help="Show suite details"
    )

    parser.add_argument(
        "--patches-workflow", action="store_true", help="Show latests build-patches workflow"
    )

    parser.add_argument(
        "--series-workflow", action="store_true", help="Show latests build-series workflow"
    )

    parser.add_argument(
        "--all-results", action="store_true", help=""
    )

    parser.add_argument(
        "--kpd", action="store_true", help="KPD conclusion debugging"
    )

    parser.add_argument(
        "--runs", action="store_true", help="Dump"
    )

    parser.add_argument(
        "--runs-all", action="store_true", help="Dump"
    )

    parser.add_argument(
        "--show-last-messages", nargs='?', const=1, type=int, metavar="N",
        help="Show last N messages (default 1)"
    )

    parser.add_argument(
        "--orphan-runs", action="store_true", help="Dump"
    )

    parser.add_argument(
        "--upstream-prs", action="store_true", help="Dump"
    )

    return parser.parse_args()

args = parse_args()

token = os.getenv('GH_TOKEN')
auth = Auth.Token(token)
g = Github(auth=auth)
# r = g.get_user().get_repo("linux")
r = g.get_organization("linux-riscv").get_repo("linux-riscv")

if args.pr:
    prs = []
    for i in args.pr:
        pr = r.get_pull(i)
        prs.append(pr)
else:
    prs = r.get_pulls(state="open")

if args.upstream_prs:
    _prs = prs
    prs = []
    for pr in _prs:
        if pr.head.ref[-5:] == "_test":
            prs.append(pr)

if args.orphan_runs:
    if args.pr:
        prs = r.get_pulls(state="open")
    print_pending_orphans(prs)
else:
    for pr in prs:
        print_pr(pr, args)
        if args.patches_workflow:
            print_patches_workflow(pr)
        if args.series_workflow:
            print_series_workflow(pr)
        if args.kpd:
            print_kpd_debug(pr)
        if args.runs or args.runs_all:
            print_runs(pr)

g.close()
